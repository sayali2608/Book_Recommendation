{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "spark = init_spark()\n",
    "sp = None\n",
    "import pandas as pd\n",
    "chunksize = 100000\n",
    "\n",
    "sp = spark.read.csv(\"ratings.csv\", header=True)\n",
    "\n",
    "\n",
    "\n",
    "#for chunk in pd.read_csv(\"ratings.csv\", chunksize=chunksize):\n",
    "#    sp = spark.createDataFrame(chunk)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rating rows: 5976479\n"
     ]
    }
   ],
   "source": [
    "print(\"number of rating rows:\",sp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|  count|\n",
      "+------+-------+\n",
      "|     3|1370916|\n",
      "|     5|1983093|\n",
      "|     1| 124195|\n",
      "|     4|2139018|\n",
      "|     2| 359257|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = sp.groupBy('rating').count()\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users for considered ratings:  53424\n"
     ]
    }
   ],
   "source": [
    "users = sp.select('user_id').distinct().collect()\n",
    "print(\"Number of Users for considered ratings: \",len(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get books info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Books 10000\n",
      "+-------+---------------+-------------------------+----------------+-------------+\n",
      "|book_id|        authors|original_publication_year|  original_title|language_code|\n",
      "+-------+---------------+-------------------------+----------------+-------------+\n",
      "|      1|Suzanne Collins|                   2008.0|The Hunger Games|          eng|\n",
      "+-------+---------------+-------------------------+----------------+-------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|average_rating|ratings_count|ratings_1|ratings_2|ratings_3|ratings_4|ratings_5|\n",
      "+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|          4.34|      4780653|    66715|   127936|   560092|  1481305|  2706317|\n",
      "+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk = spark.read.csv(\"books.csv\", header=True)\n",
    "print(\"Total Number of Books\",bk.count())\n",
    "bk1 = bk.select('book_id','authors','original_publication_year','original_title','language_code')\n",
    "bk2 = bk.select('average_rating','ratings_count','ratings_1','ratings_2','ratings_3','ratings_4','ratings_5')\n",
    "bk1.show(1)\n",
    "bk2.show(1)\n",
    "#Need for trim null data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get unique books from ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Books for considered ratings:  10000\n"
     ]
    }
   ],
   "source": [
    "books = sp.select('book_id').distinct().collect()\n",
    "print(\"Number of Books for considered ratings: \",len(books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of book-tag pairs:  999912\n",
      "+-----------------+------+-----+\n",
      "|goodreads_book_id|tag_id|count|\n",
      "+-----------------+------+-----+\n",
      "|           109515| 30574| 9998|\n",
      "|           153136| 30574| 9995|\n",
      "|         18584855| 30574|99921|\n",
      "|         13536860|  1642|  999|\n",
      "|         24480276|  8717|  999|\n",
      "+-----------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "number of book-tag pairs with more than 10 votes:  650077\n",
      "Number of tags:  13883\n",
      "Most used tags\n",
      "+------+-----+\n",
      "|tag_id|count|\n",
      "+------+-----+\n",
      "| 30574| 9971|\n",
      "|  8717| 9689|\n",
      "| 11557| 9644|\n",
      "| 22743| 9453|\n",
      "|  5207| 9134|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Tags that has been used more than 100 times: (Ignore the other tags)\n",
      "235\n"
     ]
    }
   ],
   "source": [
    "tags = spark.read.csv(\"book_tags.csv\", header=True)\n",
    "tags = tags.orderBy('count', ascending =False)\n",
    "print(\"number of book-tag pairs: \",tags.count())\n",
    "tags.show(5)\n",
    "tags = tags[tags['count']>=10]\n",
    "print(\"number of book-tag pairs with more than 10 votes: \",tags.count())\n",
    "\n",
    "\n",
    "tag = tags.groupBy('tag_id').count()\n",
    "print(\"Number of tags: \",tag.count())\n",
    "tag = tag.orderBy('count',ascending=False)\n",
    "print(\"Most used tags\")\n",
    "tag.show(5)\n",
    "tag = tag[tag['count']>=500]\n",
    "print(\"Tags that has been used more than 100 times: (Ignore the other tags)\")\n",
    "print(tag.count())\n",
    "#print(tag.select(mean(\"count\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_merge = bk.join(sp, on=['book_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5976479\n",
      "book_id intersection: 10000\n",
      "We have ratings data for all 10 000 books\n"
     ]
    }
   ],
   "source": [
    "bk_ = bk_merge.select('book_id','authors','original_publication_year','original_title','language_code','average_rating',\n",
    "                           'ratings_count','ratings_1','ratings_2','ratings_3','ratings_4','ratings_5')\n",
    "print(bk_.count())\n",
    "    \n",
    "bk_ = bk_.distinct()\n",
    "print(\"book_id intersection:\",bk_.count())\n",
    "print(\"We have ratings data for all 10 000 books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oldest books;\n",
      "+-------------------------+-----+\n",
      "|original_publication_year|count|\n",
      "+-------------------------+-----+\n",
      "|                     null|   21|\n",
      "|                    -17.0|    1|\n",
      "|                  -1750.0|    1|\n",
      "|                   -300.0|    1|\n",
      "|                   -330.0|    1|\n",
      "|                   -335.0|    1|\n",
      "|                   -350.0|    2|\n",
      "|                   -380.0|    1|\n",
      "|                   -385.0|    2|\n",
      "|                   -390.0|    1|\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Newest books;\n",
      "+-------------------------+-----+\n",
      "|original_publication_year|count|\n",
      "+-------------------------+-----+\n",
      "|                    975.0|    1|\n",
      "|                    800.0|    1|\n",
      "|                      8.0|    1|\n",
      "|                    609.0|    1|\n",
      "|                    397.0|    1|\n",
      "|                   2017.0|   11|\n",
      "|                   2016.0|  198|\n",
      "|                   2015.0|  306|\n",
      "|                   2014.0|  437|\n",
      "|                   2013.0|  518|\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------------------+-----+\n",
      "|original_publication_year|count|\n",
      "+-------------------------+-----+\n",
      "|                   2012.0|  568|\n",
      "|                   2011.0|  556|\n",
      "|                   2013.0|  518|\n",
      "|                   2010.0|  473|\n",
      "|                   2014.0|  437|\n",
      "|                   2009.0|  432|\n",
      "|                   2008.0|  383|\n",
      "|                   2007.0|  363|\n",
      "|                   2006.0|  362|\n",
      "|                   2005.0|  326|\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Unique book publication years: 294\n"
     ]
    }
   ],
   "source": [
    "year = bk_.groupBy('original_publication_year').count()\n",
    "year = year.orderBy('original_publication_year')\n",
    "print(\"Oldest books;\")\n",
    "year.show(10)\n",
    "year = year.orderBy('original_publication_year',ascending=False)\n",
    "print(\"Newest books;\")\n",
    "year.show(10)\n",
    "\n",
    "year = year.orderBy('count',ascending = False)\n",
    "year.show(10)\n",
    "print(\"Unique book publication years:\", year.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books dataset needs to be cleaned.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  4780407\n",
      "Test dataset size:  598004\n",
      "validation dataset size:  598068\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|     10|     4|\n",
      "|      1|    103|     3|\n",
      "|      1|   1041|     5|\n",
      "|      1|     11|     5|\n",
      "|      1|    119|     3|\n",
      "|      1|     13|     4|\n",
      "|      1|    136|     5|\n",
      "|      1|    138|     2|\n",
      "|      1|    148|     3|\n",
      "|      1|    150|     3|\n",
      "+-------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    111|     3|\n",
      "|      1|   2002|     5|\n",
      "|      1|   4614|     1|\n",
      "|      1|    492|     2|\n",
      "|      1|     70|     5|\n",
      "|     10|   3638|     3|\n",
      "|     10|   4363|     4|\n",
      "|     10|     63|     4|\n",
      "|    100|     10|     3|\n",
      "|    100|     11|     3|\n",
      "+-------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train,test,validate = sp.randomSplit([0.8, 0.1, 0.1],2)\n",
    "print(\"Train dataset size: \",train.count())\n",
    "print(\"Test dataset size: \",test.count())\n",
    "print(\"validation dataset size: \",validate.count())\n",
    "train.show(10)\n",
    "test.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
