{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b1df72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hp/zsdsrbcd02902_76qqkg47x80000gq/T/ipykernel_44771/1349499225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import mean\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "import sklearn\n",
    "import numpy as np \n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "\n",
    "from pyspark import SparkFiles\n",
    "spark = init_spark()\n",
    "sp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa2b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9939 111740\n"
     ]
    }
   ],
   "source": [
    "#Load Book and Tag dataset into df\n",
    "bk = spark.read.csv(\"book_clean.csv\", header=True)\n",
    "tags = spark.read.csv(\"book-tag_clean.csv\", header=True)\n",
    "print(bk.count(),tags.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f5003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|book_id|             authors|original_publication_year|               title|language_code|average_rating|ratings_count|ratings_1|ratings_2|ratings_3|ratings_4|ratings_5|\n",
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|      1|     Suzanne Collins|                     2008|The Hunger Games ...|          eng|          4.34|      4780653|    66715|   127936|   560092|  1481305|  2706317|\n",
      "|      2|J.K. Rowling, Mar...|                     1997|Harry Potter and ...|          eng|          4.44|      4602479|    75504|   101676|   455024|  1156318|  3011543|\n",
      "|      3|     Stephenie Meyer|                     2005|Twilight (Twiligh...|        en-US|          3.57|      3866839|   456191|   436802|   793319|   875073|  1355439|\n",
      "|      4|          Harper Lee|                     1960|To Kill a Mocking...|          eng|          4.25|      3198671|    60427|   117415|   446835|  1001952|  1714267|\n",
      "|      5| F. Scott Fitzgerald|                     1925|    The Great Gatsby|          eng|          3.89|      2683664|    86236|   197621|   606158|   936012|   947718|\n",
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+------+--------+\n",
      "|goodreads_book_id|tag_id|tag_name|\n",
      "+-----------------+------+--------+\n",
      "|                2| 14064|    have|\n",
      "|               34| 14064|    have|\n",
      "|              968| 14064|    have|\n",
      "|             6185| 14064|    have|\n",
      "|            10572| 14064|    have|\n",
      "+-----------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.show(5)\n",
    "tags.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08be8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_authors_df = bk.select('authors').distinct()\n",
    "distinct_title_df = bk.select('title').distinct()\n",
    "distinct_lang_df = bk.select('language_code').distinct()\n",
    "distinct_tag_df = tags.select('tag_id').distinct()\n",
    "\n",
    "num_authors = distinct_authors_df.count()\n",
    "num_title = distinct_title_df.count()\n",
    "num_lang = distinct_lang_df.count()\n",
    "num_tag = distinct_tag_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_authors : 4617\n",
      "num_title : 9903\n",
      "num_lang : 26\n",
      "num_tag : 763\n"
     ]
    }
   ],
   "source": [
    "print(\"num_authors :\",num_authors)\n",
    "print(\"num_title :\",num_title)\n",
    "print(\"num_lang :\",num_lang)\n",
    "print(\"num_tag :\",num_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e212a",
   "metadata": {},
   "source": [
    "Load and Split Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2fc7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4182526 1793953\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|     10|     4|\n",
      "|      1|     11|     5|\n",
      "|      1|     13|     4|\n",
      "|      1|     22|     3|\n",
      "|      1|     31|     4|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spliting into Training and Testing dataset 70:30 ratio\n",
    "ratings = spark.read.csv(\"ratings.csv\", header=True)\n",
    "ratings = ratings.withColumn(\"user_id\",ratings.user_id.cast('int'))\n",
    "ratings = ratings.withColumn(\"rating\",ratings.rating.cast('int'))\n",
    "ratings = ratings.withColumn(\"book_id\",ratings.book_id.cast('int'))\n",
    "train,test = ratings.randomSplit([0.7, 0.3],0)\n",
    "print(train.count(),test.count())\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d1adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('book_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9ecc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('book_id').distinct().count()\n",
    "\n",
    "##since all the books are present in both the ratings of the testing and training set,The normalization of the \n",
    "#book hotVector will be the same and therefore not necessary to be done seperatly. \n",
    "#(e.g the max and min of book year in both dataeset will be the same since the book is present in both) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d485e7",
   "metadata": {},
   "source": [
    "# Hot Vector Encoding(Item Profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e1e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|            tag_list|\n",
      "+-------+--------------------+\n",
      "|      2|[[14064, 8717, 30...|\n",
      "|   6185|[[14064, 5775, 87...|\n",
      "|  17245|[[14064, 8717, 30...|\n",
      "|  30183|[[14064, 8717, 30...|\n",
      "|  99561|[[14064, 8717, 30...|\n",
      "| 113436|[[14064, 8717, 30...|\n",
      "|1656001|[[14064, 8717, 30...|\n",
      "|6304335|[[14064, 8717, 30...|\n",
      "|   8852|[[5775, 8717, 305...|\n",
      "|      1|[[8717, 30574, 11...|\n",
      "|     13|[[8717, 30574, 11...|\n",
      "|     24|[[8717, 30574, 11...|\n",
      "|     33|[[8717, 30574, 11...|\n",
      "|    275|[[8717, 30574, 11...|\n",
      "|    304|[[8717, 30574, 11...|\n",
      "|    359|[[8717, 30574, 11...|\n",
      "|    446|[[8717, 30574, 11...|\n",
      "|    447|[[8717, 30574, 11...|\n",
      "|    621|[[8717, 30574, 21...|\n",
      "|    656|[[8717, 30574, 11...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#format tags to get list of categories of each book\n",
    "rdd1 = tags.rdd\n",
    "rdd1 = rdd1.map(lambda x: (x['goodreads_book_id'],x['tag_id'])).groupByKey()\n",
    "tags_ = rdd1.toDF([\"book_id\",\"tag_list\"])\n",
    "tags_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50967c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join tag/category  list to book dataframe\n",
    "bk = bk.join(tags_, ['book_id'], 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41dc2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- ratings_1: string (nullable = true)\n",
      " |-- ratings_2: string (nullable = true)\n",
      " |-- ratings_3: string (nullable = true)\n",
      " |-- ratings_4: string (nullable = true)\n",
      " |-- ratings_5: string (nullable = true)\n",
      " |-- tag_list: struct (nullable = true)\n",
      " |    |-- data: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- index: long (nullable = true)\n",
      " |    |-- maxindex: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.printSchema()\n",
    "bk = bk.withColumn(\"tag_list\",bk.tag_list['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null list of tags with empty list\n",
    "import pyspark.sql.functions as F\n",
    "bk = bk.withColumn(\"tag_list\",when(bk.tag_list.isNull(),F.array([])).otherwise(bk.tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfaca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|            tag_list|\n",
      "+-------+--------------------+\n",
      "|      1|[8717, 30574, 112...|\n",
      "|     10|[8717, 30574, 115...|\n",
      "|    100|                  []|\n",
      "|   1000|                  []|\n",
      "|  10000|                  []|\n",
      "|   1001|                  []|\n",
      "|   1002|                  []|\n",
      "|   1003|                  []|\n",
      "|   1004|                  []|\n",
      "|   1005|[8717, 30574, 270...|\n",
      "|   1006|                  []|\n",
      "|   1007|                  []|\n",
      "|   1008|                  []|\n",
      "|   1009|                  []|\n",
      "|    101|                  []|\n",
      "|   1010|                  []|\n",
      "|   1011|                  []|\n",
      "|   1012|                  []|\n",
      "|   1013|                  []|\n",
      "|   1014|                  []|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- ratings_1: string (nullable = true)\n",
      " |-- ratings_2: string (nullable = true)\n",
      " |-- ratings_3: string (nullable = true)\n",
      " |-- ratings_4: string (nullable = true)\n",
      " |-- ratings_5: string (nullable = true)\n",
      " |-- tag_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select('book_id','tag_list').orderBy('book_id').show()\n",
    "bk.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e371bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast non-categorical feature columns to int/float\n",
    "bk = bk.withColumn(\"original_publication_year\",bk.original_publication_year.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_count\",bk.ratings_count.cast('int'))\n",
    "bk = bk.withColumn(\"average_rating\",bk.ratings_count.cast('float'))\n",
    "bk = bk.withColumn(\"ratings_1\",bk.ratings_1.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_2\",bk.ratings_2.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_3\",bk.ratings_3.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_4\",bk.ratings_4.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_5\",bk.ratings_5.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d456a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble non-categorical features as vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"original_publication_year\", \"ratings_count\",\"average_rating\",\"ratings_1\",\"ratings_2\",\"ratings_3\",\"ratings_4\",\"ratings_5\"],\n",
    "    outputCol=\"non-categorical\")\n",
    "bk = assembler.transform(bk)\n",
    "#bk.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e0862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     non-categorical|\n",
      "+--------------------+\n",
      "|[2000.0,75469.0,7...|\n",
      "|[1994.0,80056.0,8...|\n",
      "|[2004.0,69007.0,6...|\n",
      "|[1853.0,39758.0,3...|\n",
      "|[1991.0,67753.0,6...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select(\"non-categorical\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2b99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map categorical features to numeric(vector index) \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "indexer = StringIndexer(inputCol='authors', outputCol='authors_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n",
    "indexer = StringIndexer(inputCol= 'title', outputCol='title_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol='language_code', outputCol='language-code_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b89a0bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------------+\n",
      "|authors_ind|title_ind|language-code_ind|\n",
      "+-----------+---------+-----------------+\n",
      "|     3443.0|   3177.0|              0.0|\n",
      "|     4445.0|   5961.0|              3.0|\n",
      "|       70.0|   5653.0|              0.0|\n",
      "|     4181.0|   9237.0|              0.0|\n",
      "|     3651.0|   2043.0|              0.0|\n",
      "+-----------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select(\"authors_ind\",\"title_ind\",\"language-code_ind\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36e45743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features index to hot vectors\n",
    "encoder = OneHotEncoder(inputCol='authors_ind', outputCol = 'authors_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "colorVectorizer = CountVectorizer(inputCol=\"tag_list\", outputCol=\"tag_vec\", vocabSize=763, minDF=1.0)\n",
    "colorVectorizer_model = colorVectorizer.fit(bk)\n",
    "bk = colorVectorizer_model.transform(bk)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='title_ind', outputCol = 'title_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='language-code_ind', outputCol = 'language-code_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6782d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|        authors_vec|             tag_vec|\n",
      "+-------------------+--------------------+\n",
      "|(4616,[1375],[1.0])|(537,[0,2,3,8,10,...|\n",
      "|(4616,[3772],[1.0])|(537,[1,2,62],[1....|\n",
      "| (4616,[148],[1.0])|(537,[0,1,9,57],[...|\n",
      "|(4616,[2235],[1.0])|(537,[0,1,9,16,12...|\n",
      "|   (4616,[3],[1.0])|(537,[0,1,9,132,2...|\n",
      "|(4616,[4131],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[4553],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[1507],[1.0])|(537,[0,1],[1.0,1...|\n",
      "| (4616,[335],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[2305],[1.0])|(537,[0,2,3,12],[...|\n",
      "|(4616,[3978],[1.0])|(537,[0,3,7,12,13...|\n",
      "| (4616,[165],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "| (4616,[434],[1.0])|(537,[0,2],[1.0,1...|\n",
      "| (4616,[967],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[3773],[1.0])|(537,[0,3,4,6,11,...|\n",
      "|(4616,[2111],[1.0])|(537,[0,2,3,212,2...|\n",
      "|(4616,[1420],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "| (4616,[273],[1.0])|(537,[0,1,2],[1.0...|\n",
      "|(4616,[1481],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[3554],[1.0])|(537,[0,1,2,3,241...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.filter(bk.tag_list != F.array([]) ).select('authors_vec','tag_vec').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c08a6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the vectors as 1 Hot-Vector : 15063 columns of features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"non-categorical\",\"authors_vec\",\"title_vec\",\"tag_vec\"],\n",
    "    outputCol=\"hotVector\")\n",
    "bk = assembler.transform(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939ceadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           hotVector|\n",
      "+--------------------+\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select('hotVector').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16d249aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the non-categorical features to scale 0-1\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler Transformation\n",
    "scaler = MinMaxScaler(inputCol=\"hotVector\", outputCol=\"hotVector_scaled\")\n",
    "scalerModel =  scaler.fit(bk.select(\"hotVector\"))\n",
    "bk = scalerModel.transform(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4873c2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hotVector_scaled=SparseVector(15063, {0: 0.9777, 1: 0.9627, 2: 0.9627, 3: 0.1655, 4: 0.2327, 5: 0.5734, 6: 0.7805, 7: 1.0, 205: 1.0, 7598: 1.0, 14526: 1.0, 14527: 1.0, 14528: 1.0, 14529: 1.0, 14530: 0.5, 14531: 1.0, 14533: 1.0, 14536: 1.0, 14537: 1.0, 14539: 1.0, 14540: 1.0, 14541: 1.0, 14544: 1.0, 14545: 1.0, 14548: 1.0, 14550: 1.0, 14551: 1.0, 14555: 1.0, 14556: 1.0, 14561: 1.0, 14565: 1.0, 14566: 1.0, 14568: 1.0, 14577: 1.0, 14578: 1.0, 14579: 1.0, 14582: 1.0, 14585: 1.0, 14587: 1.0, 14594: 1.0, 14602: 1.0, 14603: 1.0, 14604: 1.0, 14613: 1.0, 14622: 1.0, 14623: 1.0, 14624: 1.0, 14628: 1.0, 14638: 1.0, 14639: 1.0, 14640: 1.0, 14643: 1.0, 14648: 1.0, 14650: 1.0, 14651: 1.0, 14655: 1.0, 14660: 1.0, 14664: 1.0, 14667: 1.0, 14670: 1.0, 14675: 1.0, 14676: 1.0, 14677: 1.0, 14679: 1.0, 14691: 1.0, 14693: 1.0, 14698: 1.0, 14701: 1.0, 14703: 1.0, 14704: 1.0, 14707: 1.0, 14720: 1.0, 14728: 1.0, 14731: 1.0, 14733: 1.0, 14735: 1.0, 14745: 1.0, 14766: 1.0, 14773: 1.0, 14776: 1.0, 14778: 1.0, 14785: 1.0, 14793: 1.0, 14802: 1.0, 14803: 1.0, 14816: 1.0, 14820: 1.0, 14847: 1.0, 14849: 1.0, 14864: 1.0, 14876: 1.0, 14882: 1.0, 14886: 1.0, 14888: 1.0, 14889: 1.0, 14894: 1.0, 14897: 1.0, 14950: 1.0, 14964: 1.0, 14974: 1.0, 15029: 1.0, 15051: 1.0}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 row hot-vector example\n",
    "bk.where('book_id=2').select('hotVector_scaled').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ece3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|          hot-vector|\n",
      "+-------+--------------------+\n",
      "|   1090|[0.98104793756967...|\n",
      "|   1159|[0.97435897435897...|\n",
      "|   1436|[0.98550724637681...|\n",
      "|   1512|[0.81716833890746...|\n",
      "|   1572|[0.97101449275362...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#denseVector to vector(array)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "bk = bk.withColumn(\"hot-vector\",vector_to_array(bk.hotVector_scaled))\n",
    "bk = bk.select('book_id','hot-vector')\n",
    "bk.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d9bfd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- hot-vector: array (nullable = false)\n",
      " |    |-- element: double (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d46aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "#function to build a user profile with user_id as input\n",
    "def get_user_profile(user_id,ratings,books):\n",
    "        \n",
    "        #get high ratings of the user(4 and 5)\n",
    "        ratings = ratings.filter((ratings.user_id==user_id) & ((ratings.rating== 4) | (ratings.rating==5)))\n",
    "        items_count = ratings.count()\n",
    "        \n",
    "        if items_count > 0:\n",
    "            \n",
    "            #get the books that was read and highly rated by the user\n",
    "            items = books.join(ratings,['book_id'],'inner')\n",
    "            count = items.count()\n",
    "            \n",
    "            #convert to rdd for easy computations \n",
    "            rdd_HV = items.select('hot-vector').rdd\n",
    "            rdd_HV = rdd_HV.map(lambda x: x['hot-vector'])\n",
    "            #rdd_HV = rdd_HV.reduce(lambda x,y: x+y)\n",
    "            arr = np.array(rdd_HV.collect())\n",
    "            \n",
    "            #aggregate the highly rated book profile to get user profile\n",
    "            print(arr.shape)\n",
    "            return np.add.reduce(arr)/count\n",
    "\n",
    "        \n",
    "#function that return sorted cosine distances of unread books by a user\n",
    "def get_cosine_distance(user_id,ratings,bk):\n",
    "    \n",
    "    #get the user profile\n",
    "    print(\"Getting User Profile..\")\n",
    "    user_profile = get_user_profile(user_id,train,bk)\n",
    "    print(\"User Profile:\",user_profile)\n",
    "    \n",
    "    #get books that has not been rated by the user\n",
    "    print(\"Getting Book Not Read By User..\")\n",
    "    books = ratings.filter(ratings.user_id == user_id).select('book_id').withColumn('read',lit('True'))\n",
    "    books = bk.join(books,['book_id'],'left_outer')\n",
    "    not_read = books.filter(books.read.isNull()).select('book_id','hot-vector').rdd\n",
    "    print(\"Book Not Read: \",not_read.count())\n",
    "    \n",
    "    #compute the cosine distance of the book profiles and the user profile\n",
    "    print(\"Computing Cosine Distances..\")\n",
    "    not_read = not_read.map(lambda x: (x['book_id'],x['hot-vector']))\n",
    "    not_read = not_read.map(lambda x: (x[0],np.array(x[1])))\n",
    "    \n",
    "    #sort by cosine distance( smaller cosine distance: better)\n",
    "    similarity = not_read.map(lambda x: (distance.cosine(x[1] , user_profile ),x[0]))\n",
    "    similarity = similarity.sortByKey()\n",
    "    print(\"Complete\")\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "525b989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting User Profile..\n",
      "(36, 15063)\n",
      "User Profile: [0.95423015 0.11500936 0.11500936 ... 0.         0.02777778 0.        ]\n",
      "Getting Book Not Read By User..\n",
      "Book Not Read:  9895\n",
      "Computing Cosine Distances..\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cos_d = get_cosine_distance(2,train,bk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06a9beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|    cosine-distance|book_id|\n",
      "+-------------------+-------+\n",
      "| 0.4404359374374116|   5373|\n",
      "| 0.4468569747115929|   4415|\n",
      "|0.46440976734530204|    231|\n",
      "|0.46715485848458793|     36|\n",
      "| 0.4733138265736211|   2528|\n",
      "| 0.4734425316019377|   3378|\n",
      "|0.47345937469222243|   3384|\n",
      "| 0.4734999836164072|   9589|\n",
      "|0.47379208911869797|   9913|\n",
      "| 0.4739809814556929|   6159|\n",
      "+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recommend(top=10,user_id):\n",
    "    \n",
    "    cos_d = get_cosine_distance(user_id,train,bk)    \n",
    "    cos_d = cos_d.map(lambda x: (float(x[0]), int(x[1])))\n",
    "    cos_d = cos_d.toDF([\"cosine-distance\",\"book_id\"])\n",
    "    cos_d = cos_d.limit(top)\n",
    "    cos_d.show(10)\n",
    "    \n",
    "    #return cos_d.select('book_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_d = cos_d.map(lambda x: (float(x[0]), int(x[1])))\n",
    "cos_d = cos_d.toDF([\"cosine-distance\",\"book_id\"])\n",
    "cos_d = cos_d.limit(20)\n",
    "cos_d.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03feaf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.where('user_id=2').join(cos_d,['book_id'],'inner').show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
