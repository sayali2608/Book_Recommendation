{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b1df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import mean\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "import sklearn\n",
    "import numpy as np \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "\n",
    "from pyspark import SparkFiles\n",
    "spark = init_spark()\n",
    "sp = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba96fa",
   "metadata": {},
   "source": [
    "# Content Based Book Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa2b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9939 111740\n"
     ]
    }
   ],
   "source": [
    "#Load Book and Tag dataset into df\n",
    "bk = spark.read.csv(\"book_clean.csv\", header=True)\n",
    "tags = spark.read.csv(\"book-tag_clean.csv\", header=True)\n",
    "print(bk.count(),tags.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f5003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|book_id|             authors|original_publication_year|               title|language_code|average_rating|ratings_count|ratings_1|ratings_2|ratings_3|ratings_4|ratings_5|\n",
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "|      1|     Suzanne Collins|                     2008|The Hunger Games ...|          eng|          4.34|      4780653|    66715|   127936|   560092|  1481305|  2706317|\n",
      "|      2|J.K. Rowling, Mar...|                     1997|Harry Potter and ...|          eng|          4.44|      4602479|    75504|   101676|   455024|  1156318|  3011543|\n",
      "|      3|     Stephenie Meyer|                     2005|Twilight (Twiligh...|        en-US|          3.57|      3866839|   456191|   436802|   793319|   875073|  1355439|\n",
      "|      4|          Harper Lee|                     1960|To Kill a Mocking...|          eng|          4.25|      3198671|    60427|   117415|   446835|  1001952|  1714267|\n",
      "|      5| F. Scott Fitzgerald|                     1925|    The Great Gatsby|          eng|          3.89|      2683664|    86236|   197621|   606158|   936012|   947718|\n",
      "+-------+--------------------+-------------------------+--------------------+-------------+--------------+-------------+---------+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+------+--------+\n",
      "|goodreads_book_id|tag_id|tag_name|\n",
      "+-----------------+------+--------+\n",
      "|                2| 14064|    have|\n",
      "|               34| 14064|    have|\n",
      "|              968| 14064|    have|\n",
      "|             6185| 14064|    have|\n",
      "|            10572| 14064|    have|\n",
      "+-----------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.show(5)\n",
    "tags.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08be8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_authors_df = bk.select('authors').distinct()\n",
    "distinct_title_df = bk.select('title').distinct()\n",
    "distinct_lang_df = bk.select('language_code').distinct()\n",
    "distinct_tag_df = tags.select('tag_id').distinct()\n",
    "\n",
    "num_authors = distinct_authors_df.count()\n",
    "num_title = distinct_title_df.count()\n",
    "num_lang = distinct_lang_df.count()\n",
    "num_tag = distinct_tag_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cf1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_authors : 4617\n",
      "num_title : 9903\n",
      "num_lang : 26\n",
      "num_tag : 763\n"
     ]
    }
   ],
   "source": [
    "#Categorical features\n",
    "print(\"num_authors :\",num_authors)\n",
    "print(\"num_title :\",num_title)\n",
    "print(\"num_lang :\",num_lang)\n",
    "print(\"num_tag :\",num_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e212a",
   "metadata": {},
   "source": [
    "Load and Split Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2fc7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4182526 1793953\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|     10|     4|\n",
      "|      1|     11|     5|\n",
      "|      1|     13|     4|\n",
      "|      1|     22|     3|\n",
      "|      1|     31|     4|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spliting into Training and Testing dataset 70:30 ratio\n",
    "ratings = spark.read.csv(\"ratings.csv\", header=True)\n",
    "ratings = ratings.withColumn(\"user_id\",ratings.user_id.cast('int'))\n",
    "ratings = ratings.withColumn(\"rating\",ratings.rating.cast('int'))\n",
    "ratings = ratings.withColumn(\"book_id\",ratings.book_id.cast('int'))\n",
    "\n",
    "train,test = ratings.randomSplit([0.7, 0.3],0)\n",
    "print(train.count(),test.count())\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d1adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('book_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9ecc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select('book_id').distinct().count()\n",
    "\n",
    "##since all the books are present in both the ratings of the testing and training set,The normalization of the \n",
    "#book hotVector will be the same and therefore not necessary to be done seperatly. \n",
    "#(e.g the max and min of book year in both dataset will be the same since the book is present in both) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d485e7",
   "metadata": {},
   "source": [
    "# Hot Vector Encoding(Item Profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3f46f",
   "metadata": {},
   "source": [
    "Merging the book tags from tag dataset to book dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e1e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|            tag_list|\n",
      "+-------+--------------------+\n",
      "|      2|[[14064, 8717, 30...|\n",
      "|   6185|[[14064, 5775, 87...|\n",
      "|  17245|[[14064, 8717, 30...|\n",
      "|  30183|[[14064, 8717, 30...|\n",
      "|  99561|[[14064, 8717, 30...|\n",
      "| 113436|[[14064, 8717, 30...|\n",
      "|1656001|[[14064, 8717, 30...|\n",
      "|6304335|[[14064, 8717, 30...|\n",
      "|   8852|[[5775, 8717, 305...|\n",
      "|      1|[[8717, 30574, 11...|\n",
      "|     13|[[8717, 30574, 11...|\n",
      "|     24|[[8717, 30574, 11...|\n",
      "|     33|[[8717, 30574, 11...|\n",
      "|    275|[[8717, 30574, 11...|\n",
      "|    304|[[8717, 30574, 11...|\n",
      "|    359|[[8717, 30574, 11...|\n",
      "|    446|[[8717, 30574, 11...|\n",
      "|    447|[[8717, 30574, 11...|\n",
      "|    621|[[8717, 30574, 21...|\n",
      "|    656|[[8717, 30574, 11...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#format tags to get list of categories of each book\n",
    "rdd1 = tags.rdd\n",
    "rdd1 = rdd1.map(lambda x: (x['goodreads_book_id'],x['tag_id'])).groupByKey()\n",
    "tags_ = rdd1.toDF([\"book_id\",\"tag_list\"])\n",
    "tags_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50967c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join tag/category list to book dataframe\n",
    "bk = bk.join(tags_, ['book_id'], 'left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41dc2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- ratings_1: string (nullable = true)\n",
      " |-- ratings_2: string (nullable = true)\n",
      " |-- ratings_3: string (nullable = true)\n",
      " |-- ratings_4: string (nullable = true)\n",
      " |-- ratings_5: string (nullable = true)\n",
      " |-- tag_list: struct (nullable = true)\n",
      " |    |-- data: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- index: long (nullable = true)\n",
      " |    |-- maxindex: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.printSchema()\n",
    "bk = bk.withColumn(\"tag_list\",bk.tag_list['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null list of tags with empty list\n",
    "import pyspark.sql.functions as F\n",
    "bk = bk.withColumn(\"tag_list\",when(bk.tag_list.isNull(),F.array([])).otherwise(bk.tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfaca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|            tag_list|\n",
      "+-------+--------------------+\n",
      "|      1|[8717, 30574, 112...|\n",
      "|     10|[8717, 30574, 115...|\n",
      "|    100|                  []|\n",
      "|   1000|                  []|\n",
      "|  10000|                  []|\n",
      "|   1001|                  []|\n",
      "|   1002|                  []|\n",
      "|   1003|                  []|\n",
      "|   1004|                  []|\n",
      "|   1005|[8717, 30574, 270...|\n",
      "|   1006|                  []|\n",
      "|   1007|                  []|\n",
      "|   1008|                  []|\n",
      "|   1009|                  []|\n",
      "|    101|                  []|\n",
      "|   1010|                  []|\n",
      "|   1011|                  []|\n",
      "|   1012|                  []|\n",
      "|   1013|                  []|\n",
      "|   1014|                  []|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- ratings_1: string (nullable = true)\n",
      " |-- ratings_2: string (nullable = true)\n",
      " |-- ratings_3: string (nullable = true)\n",
      " |-- ratings_4: string (nullable = true)\n",
      " |-- ratings_5: string (nullable = true)\n",
      " |-- tag_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select('book_id','tag_list').orderBy('book_id').show()\n",
    "bk.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8097b",
   "metadata": {},
   "source": [
    "Non-categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e371bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast non-categorical feature columns to int/float\n",
    "bk = bk.withColumn(\"original_publication_year\",bk.original_publication_year.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_count\",bk.ratings_count.cast('int'))\n",
    "bk = bk.withColumn(\"average_rating\",bk.ratings_count.cast('float'))\n",
    "bk = bk.withColumn(\"ratings_1\",bk.ratings_1.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_2\",bk.ratings_2.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_3\",bk.ratings_3.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_4\",bk.ratings_4.cast('int'))\n",
    "bk = bk.withColumn(\"ratings_5\",bk.ratings_5.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d456a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble non-categorical features as vector\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"original_publication_year\", \"ratings_count\",\"average_rating\",\"ratings_1\",\"ratings_2\",\"ratings_3\",\"ratings_4\",\"ratings_5\"],\n",
    "    outputCol=\"non-categorical\")\n",
    "bk = assembler.transform(bk)\n",
    "#bk.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e0862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     non-categorical|\n",
      "+--------------------+\n",
      "|[2000.0,75469.0,7...|\n",
      "|[1994.0,80056.0,8...|\n",
      "|[2004.0,69007.0,6...|\n",
      "|[1853.0,39758.0,3...|\n",
      "|[1991.0,67753.0,6...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select(\"non-categorical\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e8f3b",
   "metadata": {},
   "source": [
    "Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2b99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map categorical features to numeric(vector index) \n",
    "\n",
    "indexer = StringIndexer(inputCol='authors', outputCol='authors_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n",
    "indexer = StringIndexer(inputCol= 'title', outputCol='title_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol='language_code', outputCol='language-code_ind')\n",
    "bk=indexer.fit(bk).transform(bk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b89a0bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------------+\n",
      "|authors_ind|title_ind|language-code_ind|\n",
      "+-----------+---------+-----------------+\n",
      "|     3443.0|   3177.0|              0.0|\n",
      "|     4445.0|   5961.0|              3.0|\n",
      "|       70.0|   5653.0|              0.0|\n",
      "|     4181.0|   9237.0|              0.0|\n",
      "|     3651.0|   2043.0|              0.0|\n",
      "+-----------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select(\"authors_ind\",\"title_ind\",\"language-code_ind\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36e45743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features index to hot vectors\n",
    "encoder = OneHotEncoder(inputCol='authors_ind', outputCol = 'authors_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n",
    "\n",
    "colorVectorizer = CountVectorizer(inputCol=\"tag_list\", outputCol=\"tag_vec\", vocabSize=763, minDF=1.0)\n",
    "colorVectorizer_model = colorVectorizer.fit(bk)\n",
    "bk = colorVectorizer_model.transform(bk)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='title_ind', outputCol = 'title_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='language-code_ind', outputCol = 'language-code_vec')\n",
    "bk = encoder.fit(bk).transform(bk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6782d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|        authors_vec|             tag_vec|\n",
      "+-------------------+--------------------+\n",
      "|(4616,[1375],[1.0])|(537,[0,2,3,8,10,...|\n",
      "|(4616,[3772],[1.0])|(537,[1,2,62],[1....|\n",
      "| (4616,[148],[1.0])|(537,[0,1,9,57],[...|\n",
      "|(4616,[2235],[1.0])|(537,[0,1,9,16,12...|\n",
      "|   (4616,[3],[1.0])|(537,[0,1,9,132,2...|\n",
      "|(4616,[4131],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[4553],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[1507],[1.0])|(537,[0,1],[1.0,1...|\n",
      "| (4616,[335],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[2305],[1.0])|(537,[0,2,3,12],[...|\n",
      "|(4616,[3978],[1.0])|(537,[0,3,7,12,13...|\n",
      "| (4616,[165],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "| (4616,[434],[1.0])|(537,[0,2],[1.0,1...|\n",
      "| (4616,[967],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[3773],[1.0])|(537,[0,3,4,6,11,...|\n",
      "|(4616,[2111],[1.0])|(537,[0,2,3,210,2...|\n",
      "|(4616,[1420],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "| (4616,[273],[1.0])|(537,[0,1,2],[1.0...|\n",
      "|(4616,[1481],[1.0])|(537,[0,1,2,3,4,5...|\n",
      "|(4616,[3554],[1.0])|(537,[0,1,2,3,243...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.filter(bk.tag_list != F.array([]) ).select('authors_vec','tag_vec').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c5674",
   "metadata": {},
   "source": [
    "Assemble all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c08a6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the vectors as 1 Hot-Vector : 15063 columns of features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"non-categorical\",\"authors_vec\",\"title_vec\",\"tag_vec\"],outputCol=\"hotVector\")\n",
    "bk = assembler.transform(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939ceadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           hotVector|\n",
      "+--------------------+\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "|(15063,[0,1,2,3,4...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk.select('hotVector').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84510650",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16d249aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the non-categorical features to scale 0-1\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler Transformation\n",
    "scaler = MinMaxScaler(inputCol=\"hotVector\", outputCol=\"hotVector_scaled\")\n",
    "scalerModel =  scaler.fit(bk.select(\"hotVector\"))\n",
    "bk = scalerModel.transform(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4873c2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hotVector_scaled=SparseVector(15063, {0: 0.9777, 1: 0.9627, 2: 0.9627, 3: 0.1655, 4: 0.2327, 5: 0.5734, 6: 0.7805, 7: 1.0, 205: 1.0, 7598: 1.0, 14526: 1.0, 14527: 1.0, 14528: 1.0, 14529: 1.0, 14530: 0.5, 14531: 1.0, 14533: 1.0, 14536: 1.0, 14537: 1.0, 14539: 1.0, 14540: 1.0, 14541: 1.0, 14544: 1.0, 14545: 1.0, 14548: 1.0, 14550: 1.0, 14551: 1.0, 14555: 1.0, 14556: 1.0, 14561: 1.0, 14565: 1.0, 14566: 1.0, 14568: 1.0, 14577: 1.0, 14578: 1.0, 14579: 1.0, 14582: 1.0, 14585: 1.0, 14586: 1.0, 14594: 1.0, 14602: 1.0, 14603: 1.0, 14604: 1.0, 14612: 1.0, 14621: 1.0, 14622: 1.0, 14626: 1.0, 14628: 1.0, 14638: 1.0, 14639: 1.0, 14640: 1.0, 14643: 1.0, 14648: 1.0, 14650: 1.0, 14651: 1.0, 14656: 1.0, 14661: 1.0, 14664: 1.0, 14667: 1.0, 14670: 1.0, 14674: 1.0, 14675: 1.0, 14677: 1.0, 14679: 1.0, 14691: 1.0, 14694: 1.0, 14695: 1.0, 14697: 1.0, 14700: 1.0, 14703: 1.0, 14716: 1.0, 14727: 1.0, 14728: 1.0, 14731: 1.0, 14732: 1.0, 14733: 1.0, 14755: 1.0, 14757: 1.0, 14759: 1.0, 14770: 1.0, 14778: 1.0, 14796: 1.0, 14798: 1.0, 14802: 1.0, 14804: 1.0, 14816: 1.0, 14821: 1.0, 14832: 1.0, 14845: 1.0, 14866: 1.0, 14871: 1.0, 14872: 1.0, 14875: 1.0, 14882: 1.0, 14887: 1.0, 14889: 1.0, 14945: 1.0, 14946: 1.0, 14964: 1.0, 14985: 1.0, 14998: 1.0, 15045: 1.0}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 row hot-vector example\n",
    "bk.where('book_id=2').select('hotVector_scaled').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ece3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|book_id|          hot-vector|\n",
      "+-------+--------------------+\n",
      "|   1090|[0.98104793756967...|\n",
      "|   1159|[0.97435897435897...|\n",
      "|   1436|[0.98550724637681...|\n",
      "|   1512|[0.81716833890746...|\n",
      "|   1572|[0.97101449275362...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#denseVector to vector(array)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "bk_arr = bk.withColumn(\"hot-vector\",vector_to_array(bk.hotVector_scaled))\n",
    "bk_arr = bk_arr.select('book_id','hot-vector')\n",
    "bk_arr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d9bfd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- hot-vector: array (nullable = false)\n",
      " |    |-- element: double (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk_arr.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cd1ad",
   "metadata": {},
   "source": [
    "# Recommenation using Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26507fab",
   "metadata": {},
   "source": [
    "Functions for recommending books and predicting ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d46aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build a user profile with user_id as input\n",
    "\n",
    "#User profile : Aggregate of the profile of books that was rated 4 or 5 by the user from the training set \n",
    "\n",
    "def get_user_profile(user_id,ratings,books):\n",
    "        \n",
    "        #get high ratings of the user(4 and 5)\n",
    "        ratings = ratings.filter((ratings.user_id==user_id) & ((ratings.rating== 4) | (ratings.rating==5)))\n",
    "        items_count = ratings.count()\n",
    "        \n",
    "        if items_count > 2:\n",
    "            \n",
    "            #get the books that was read and highly rated by the user\n",
    "            items = books.join(ratings,['book_id'],'inner')\n",
    "            count = items.count()\n",
    "            \n",
    "            #convert to rdd for easy computations \n",
    "            rdd_HV = items.select('hot-vector').rdd\n",
    "            rdd_HV = rdd_HV.map(lambda x: x['hot-vector'])\n",
    "            arr = np.array(rdd_HV.collect())\n",
    "            \n",
    "            #aggregate the highly rated book profile to get user profile\n",
    "            print(arr.shape)\n",
    "            return np.add.reduce(arr)/count\n",
    "        else:\n",
    "            print(\"Not enough training sample to build user profile\")\n",
    "            return []\n",
    "        \n",
    "#function that return sorted cosine distances of unread books by a user\n",
    "#cosine distance of user profile and book profiles\n",
    "def get_cosine_distance(user_id,ratings,bk):\n",
    "    \n",
    "    #get the user profile\n",
    "    print(\"Getting User Profile..\")\n",
    "    user_profile = get_user_profile(user_id,train,bk)\n",
    "    if len(user_profile)==0:\n",
    "        return None\n",
    "    print(\"User Profile:\",user_profile)\n",
    "    \n",
    "    #get books that has not been rated by the user\n",
    "    print(\"Getting Book Not Read By User..\")\n",
    "    books = ratings.filter(ratings.user_id == user_id).select('book_id').withColumn('read',lit('True'))\n",
    "    books = bk.join(books,['book_id'],'left_outer')\n",
    "    not_read = books.filter(books.read.isNull()).select('book_id','hot-vector').rdd\n",
    "    print(\"Book Not Read: \",not_read.count())\n",
    "    \n",
    "    #compute the cosine distance of the book profiles and the user profile\n",
    "    print(\"Computing Cosine Distances..\")\n",
    "    not_read = not_read.map(lambda x: (x['book_id'],x['hot-vector']))\n",
    "    not_read = not_read.map(lambda x: (x[0],np.array(x[1])))\n",
    "    cosine_distance = not_read.map(lambda x: (distance.cosine(x[1] , user_profile ),x[0]))\n",
    "    \n",
    "    #sort by cosine distance( smaller cosine distance: better)\n",
    "    cosine_distance = cosine_distance.sortByKey()\n",
    "    print(\"Complete\")\n",
    "    \n",
    "    return cosine_distance\n",
    "\n",
    "\n",
    "#function to get top n recommended books based on cosine distance\n",
    "#recommend top 10 book that has a lower cosine distance to the user's profile\n",
    "def recommend_top_book(user_id,top=10):\n",
    "    \n",
    "    cos_d = get_cosine_distance(user_id,train,bk_arr)    \n",
    "    if cos_d == None:\n",
    "        print(\"Prediction not possible\")\n",
    "        return None\n",
    "    \n",
    "    cos_d = cos_d.map(lambda x: (float(x[0]), int(x[1])))\n",
    "    cos_d = cos_d.toDF([\"cosine-distance\",\"book_id\"])\n",
    "    cos_d = cos_d.limit(top)\n",
    "    cos_d.show(10)\n",
    "    \n",
    "    return cos_d\n",
    "\n",
    "#function that get top items based on rating prediction (cosine similarity scaled to 1-5)\n",
    "# cosine similarity = 1-cosine distance (range 0->1)\n",
    "def predict_ratings(user_id,ratings,bk):\n",
    "    \n",
    "    #get the user profile\n",
    "    print(\"Getting User Profile..\")\n",
    "    user_profile = get_user_profile(user_id,train,bk)\n",
    "    print(\"User Profile:\",user_profile)\n",
    "    \n",
    "    #get books that has not been rated by the user\n",
    "    print(\"Getting Book Not Read By User..\")\n",
    "    books = ratings.filter(ratings.user_id == user_id).select('book_id').withColumn('read',lit('True'))\n",
    "    books = bk.join(books,['book_id'],'left_outer')\n",
    "    not_read = books.filter(books.read.isNull()).select('book_id','hot-vector').rdd\n",
    "    print(\"Book Not Read: \",not_read.count())\n",
    "    \n",
    "    #compute the cosine similarity of the book profiles and the user profile\n",
    "    print(\"Computing Cosine Similarity..\")\n",
    "    not_read = not_read.map(lambda x: (x['book_id'],x['hot-vector']))\n",
    "    not_read = not_read.map(lambda x: (x[0],np.array(x[1])))\n",
    "    similarity = not_read.map(lambda x: (1 - distance.cosine(x[1] , user_profile ),x[0]))\n",
    "    \n",
    "    #cosine similarity range: 0-1 -> scaled to range of prediction 1-5 \n",
    "    #scale to ratings 1-5\n",
    "    #new_value = ( (old_value - old_min) / (old_max - old_min) ) * (new_max - new_min) + new_min\n",
    "    print(\"Converting to rating..\")\n",
    "    rat = similarity.map(lambda x: ( (((x[0] - 0) / (1 - 0)) * (5 - 1) + 1),x[1]))\n",
    "    \n",
    "    #Convert back to spark df\n",
    "    rat = rat.map(lambda x: (float(x[0]), int(x[1])))\n",
    "    rat = rat.toDF([\"prediction\",\"book_id\"])\n",
    "    rat = rat.orderBy('prediction',ascending=False)   \n",
    "    print(\"Complete\")\n",
    "    \n",
    "    rat.show(10)\n",
    "    return rat\n",
    "\n",
    "#-----------Evaluation Functions\n",
    "\n",
    "#function that calculates top k recommendation's precision for a list of user \n",
    "def evaluate_recommend_top_book(fraction=0.1,seed=0,top=10):\n",
    "    \n",
    "    print(\"getting random subset for evaluation\")\n",
    "    #getting evaluation sub-set\n",
    "    t1 = train.groupBy('user_id').count().where('count>100')\n",
    "    t2 = test.groupBy('user_id').count().where('count>60')\n",
    "    \n",
    "    #only include user with >100 book read in training set and >60 book read in testing set\n",
    "    #sub sample to get a smaller subset based on fraction (too much to compute)\n",
    "    t1 = t1.join(t2,['user_id'],'inner').sample(withReplacement=False,fraction=fraction,seed=seed)\n",
    "    \n",
    "    \n",
    "    test_list_ = t1.select('user_id').collect()\n",
    "    test_list= []\n",
    "    for usr in test_list_:\n",
    "        test_list.append(usr['user_id'])\n",
    "\n",
    "    print(\"test user list:\", test_list)\n",
    "    \n",
    "    t = ['28343']\n",
    "    \n",
    "    #true positive\n",
    "    tp = 0\n",
    "    #false positive\n",
    "    fp = 0\n",
    "    \n",
    "    #temporarily testing for only 1 user since the computation time is too long\n",
    "    for user in t:#test_list:\n",
    "        #get sorted cosine distance\n",
    "        cos_d = get_cosine_distance(user,train,bk_arr)\n",
    "        \n",
    "        #get top k (default=10)\n",
    "        cos_d = cos_d.map(lambda x: (float(x[0]), int(x[1])))\n",
    "        cos_d = cos_d.toDF([\"cosine-distance\",\"book_id\"])\n",
    "        cos_d = cos_d.limit(top)\n",
    "        \n",
    "        #check number of book in top k that match test set(rating>3) \n",
    "        print(\"Calculating Precision..\")\n",
    "        match = test.filter((test.user_id==user) & (test.rating >= 3)).join(cos_d,['book_id'],'inner').count()\n",
    "        tp += match\n",
    "        fp += top - match\n",
    "        \n",
    "    #calculate total presision\n",
    "    precision = tp/(tp+fp)\n",
    "    print(\"precision:\",precision)\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "525b989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting User Profile..\n",
      "(63, 15063)\n",
      "User Profile: [0.98198581 0.08147422 0.08147422 ... 0.         0.         0.        ]\n",
      "Getting Book Not Read By User..\n",
      "Book Not Read:  9831\n",
      "Computing Cosine Distances..\n",
      "Complete\n",
      "+-------------------+-------+\n",
      "|    cosine-distance|book_id|\n",
      "+-------------------+-------+\n",
      "|  0.372320187762202|   5373|\n",
      "|0.37946318827467695|   4415|\n",
      "| 0.4246526870308782|    336|\n",
      "| 0.4250362047136187|    242|\n",
      "| 0.4254430141234804|    266|\n",
      "| 0.4287743826194933|   2282|\n",
      "| 0.4287780681652572|   2974|\n",
      "| 0.4288884249986521|   5891|\n",
      "|0.42912548320166477|   1535|\n",
      "| 0.4291912343345733|    674|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#recommending top 10 book for a user of id '28343'\n",
    "r = recommend_top_book('28343')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32560550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------+------+\n",
      "|book_id|    cosine-distance|user_id|rating|\n",
      "+-------+-------------------+-------+------+\n",
      "|    266| 0.4254430141234804|  28343|     4|\n",
      "|   1535|0.42912548320166477|  28343|     3|\n",
      "|   2974| 0.4287780681652572|  28343|     4|\n",
      "+-------+-------------------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check how many of the recommendation was read (in test set)\n",
    "match = r.join(test.where('user_id=28343'),['book_id'],'inner')\n",
    "match.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90a11eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting User Profile..\n",
      "(63, 15063)\n",
      "User Profile: [0.98198581 0.08147422 0.08147422 ... 0.         0.         0.        ]\n",
      "Getting Book Not Read By User..\n",
      "Book Not Read:  9831\n",
      "Computing Cosine Similarity..\n",
      "Converting to rating..\n",
      "Complete\n",
      "+------------------+-------+\n",
      "|        prediction|book_id|\n",
      "+------------------+-------+\n",
      "| 3.510719248951192|   5373|\n",
      "| 3.482147246901292|   4415|\n",
      "| 3.301389251876487|    336|\n",
      "|3.2998551811455252|    242|\n",
      "|3.2982279435060784|    266|\n",
      "| 3.284902469522027|   2282|\n",
      "| 3.284887727338971|   2974|\n",
      "|3.2844463000053916|   5891|\n",
      "| 3.283498067193341|   1535|\n",
      "| 3.283235062661707|    674|\n",
      "+------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example rating prediction for user 28343\n",
    "\n",
    "u1 = '28343'\n",
    "rat = predict_ratings(u1,train,bk_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "500ec43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+------+\n",
      "|book_id|        prediction|user_id|rating|\n",
      "+-------+------------------+-------+------+\n",
      "|    148| 3.096848711656899|  28343|     3|\n",
      "|   2488| 3.050374516674024|  28343|     3|\n",
      "|    133|2.9497537168965007|  28343|     4|\n",
      "|   1871|3.0199833163907366|  28343|     4|\n",
      "|     12| 3.141642464346574|  28343|     4|\n",
      "|   8067| 3.057451790816606|  28343|     4|\n",
      "|    122|2.6874890249750503|  28343|     3|\n",
      "|   5025| 3.082004342837952|  28343|     4|\n",
      "|    232| 3.053569513730684|  28343|     2|\n",
      "|   1425|3.0584953302345954|  28343|     4|\n",
      "|    259|3.0955098194704944|  28343|     3|\n",
      "|     52|3.1501085046167216|  28343|     4|\n",
      "|    182|3.1395863782494393|  28343|     4|\n",
      "|    280|3.1265939600025243|  28343|     4|\n",
      "|     20|3.1418766715950217|  28343|     3|\n",
      "|     57|3.1273075642940817|  28343|     5|\n",
      "|   1032| 2.779275134337932|  28343|     4|\n",
      "|    266|3.2982279435060784|  28343|     4|\n",
      "|    415|2.5252362217527615|  28343|     3|\n",
      "|    227|3.2024416133593085|  28343|     4|\n",
      "+-------+------------------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "rmse: 1.0147359713133397\n"
     ]
    }
   ],
   "source": [
    "#Evaluate rating prediction for user 28343\n",
    "\n",
    "evaluation = rat.join(test.where('user_id='+u1),['book_id'],'inner')\n",
    "evaluation.show()\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(evaluation)\n",
    "print(\"rmse:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5324861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting random subset for evaluation\n",
      "test user list: [32923, 33207, 18100, 38082, 49297, 32745, 23291, 3662, 12417, 5267, 22496, 9246, 47476, 35111, 35146, 49295, 27127, 52036, 44019, 12771]\n",
      "Getting User Profile..\n",
      "(63, 15063)\n",
      "User Profile: [0.98198581 0.08147422 0.08147422 ... 0.         0.         0.        ]\n",
      "Getting Book Not Read By User..\n",
      "Book Not Read:  9831\n",
      "Computing Cosine Distances..\n",
      "Complete\n",
      "Calculating Precision..\n",
      "precision: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 precision for user u1 recommendation \n",
    "evaluate_recommend_top_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0c20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db025406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9beab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdcb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f19fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03feaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23b5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2256bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607964c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
